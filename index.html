<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Jingyao Li</title>
  
  <meta name="author" content="Jingyao Li">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ü•ù</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:1280px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">

        <!-- 1 INTRO -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:1%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Jingyao Li</name>
              </p>
              <p>
                Hi! Here is LI jingyao. I am a Ph.D. student at <a href="https://www.cuhk.edu.hk/english/index.html"> CUHK</a>, advised by <a href="https://jiaya.me">Prof. Jiaya Jia</a>.
              </p>
              <p>
                Before that, I received my B.Sc. degree at <a href="http://en.xjtu.edu.cn/"> Xi'anJiaotong University</a>.
              </p>
              <p>
                My primary research interest is in Large Language Models. 
              </p>
              <p style="text-align:center">
                <a href="jingyao.li@link.cuhk.edu.hk">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?hl=zh-CN&user=mqrKmvcAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/JulietLJY">Github</a>
              </p>
              <p>
                ÊàëÊ≠£Âú®ÂØªÊ±Ç26Â±äÁßãÊãõÊØï‰∏öÊú∫‰ºöÔºåÊ¨¢ËøéËÅîÁ≥ª~
              </p>
            </td>
            <td style="padding:5%;width:40%;max-width:40%" onmouseout="intro_stop()" onmouseover="intro_start()">
              <div class="one" style="display: inline;">
                <div class="two" id='intro' style="display: inline;">
                  <img style="width:auto; max-height:200px; display:block;" src="images/jingyao_li.jpg">
                </div>
                <img style="width:auto; max-height:200px; display:block;" src="images/jingyao_li.jpg">
              </div>
              <script type="text/javascript">
                function intro_start() {
                  document.getElementById('intro').style.opacity = "1";
                }
            
                function intro_stop() {
                  document.getElementById('intro').style.opacity = "0";
                }
                intro_stop()
              </script>
            </td>
          </tr>
        </tbody></table>

        <!-- 2 Research -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:1%;width:100%;vertical-align:middle">
              <heading>Selected Research</heading>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;padding:3px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr class="single_element" style="width:100%">
            <td style="padding:20px;width:100%;vertical-align:middle">
              <papertitle>(CVPR2023)</papertitle> Rethinking Out-of-Distribution Detection: Masked Image Modeling is All You Need
              <br>
              <p></p>
              <a style="color:#ffac4d">Jingyao Li</a>, Pengguang Chen, Shaozuo Yu, Zexin He, Shu Liu, Jiaya Jia.
              [
              <a href="https://arxiv.org/abs/2302.02615" target="blank_">Paper</a> /
              <a href="https://github.com/dvlab-research/MOOD">Code</a> /
              <a href="https://cvpr2023.thecvf.com/virtual/2023/poster/23070" target="blank_">Project Page</a>
              ]
            </td>
          </tr>

          <tr class="single_element" style="width:100%">
            <td style="padding:20px;width:100%;vertical-align:middle">
              <papertitle>(TPAMI2023)</papertitle> BAL: Balancing Diversity and Novelty for Active Learning
              <br>
              <p></p>
              <a style="color:#ffac4d">Jingyao Li</a>, Pengguang Chen, Shaozuo Yu, Shu Liu, Jiaya Jia.
              [
              <a href="https://ieeexplore.ieee.org/abstract/document/10372131" target="blank_">Paper</a> /
              <a href="https://github.com/JulietLJY/BAL">Code</a>
              ]
            </td>
          </tr>

          <tr class="single_element" style="width:100%">
            <td style="padding:20px;width:100%;vertical-align:middle">
              <papertitle>(TPAMI2024)</papertitle> MOODv2: Masked Image Modeling for Out-of-Distribution Detection
              <br>
              <p></p>
              <a style="color:#ffac4d">Jingyao Li</a>, Pengguang Chen, Shaozuo Yu, Shu Liu, Jiaya Jia.
              [
              <a href="https://arxiv.org/abs/2401.02611" target="blank_">Paper</a> /
              <a href="https://github.com/dvlab-research/MOOD">Code</a>
              ]
            </td>
          </tr>

          <tr class="single_element" style="width:100%">
            <td style="padding:20px;width:100%;vertical-align:middle">
              <papertitle>(TPAMI2024)</papertitle> TagCLIP: Improving Discrimination Ability of Open-Vocabulary Semantic Segmentation
              <br>
              <p></p>
              <a style="color:#ffac4d">Jingyao Li</a>, Pengguang Chen, Shengju Qian, Jiaya Jia.
              [
              <a href="https://arxiv.org/abs/2304.07547" target="blank_">Paper</a> /
              <a href="https://github.com/dvlab-research/TagCLIP">Code</a>
              ]
            </td>
          </tr>

          <tr class="single_element" style="width:100%">
            <td style="padding:20px;width:100%;vertical-align:middle">
              <papertitle>(Neurips2024)</papertitle> MR-BEN: A Comprehensive Meta-Reasoning Benchmark for Large Language Models
              <br>
              <p></p>
              Zhongshen Zeng, Yinhong Liu, Yingjia Wan, <a style="color:#ffac4d">Jingyao Li</a>, Pengguang Chen, Jianbo Dai, Yuxuan Yao, Rongwu Xu, Zehan Qi, Wanru Zhao, Linling Shen, Jianqiao Lu, Haochen Tan, Yukang Chen, Hao Zhang, Zhan Shi, Bailin Wang, Zhijiang Guo, Jiaya Jia.
              [
              <a href="https://arxiv.org/abs/2406.13975" target="blank_">Paper</a> /
              <a href="https://github.com/dvlab-research/Mr-Ben">Code</a> /
              <a href="https://huggingface.co/datasets/Randolphzeng/Mr-Ben">Dataset</a> /
              <a href="https://randolph-zeng.github.io/Mr-Ben.github.io/">Project Page</a>
              ]
            </td>
          </tr>

          <tr class="single_element" style="width:100%">
            <td style="padding:20px;width:100%;vertical-align:middle">
              <papertitle>(Neurips2024)</papertitle> DAPE: Data-Adaptive Positional Encoding for Length Extrapolation
              <br>
              <p></p>
              Chuanyang Zheng, Yihang Gao, Han Shi, Minbin Huang, <a style="color:#ffac4d">Jingyao Li</a>, Jing Xiong, Xiaozhe Ren, Michael Ng, Xin Jiang, Zhenguo Li, Yu Li.
              [
              <a href="https://arxiv.org/abs/2405.14722" target="blank_">Paper</a> /
              <a href="https://github.com/chuanyang-Zheng/DAPE">Code</a> /
              <a href="https://news.qq.com/rain/a/20241012A04J4Z00">Coverage</a>
              ]
            </td>
          </tr>

          <tr class="single_element" style="width:100%">
            <td style="padding:20px;width:100%;vertical-align:middle">
              <papertitle>(COLING2025)</papertitle> QuickLLaMA: Query-aware Inference Acceleration for Large Language Models
              <br>
              <p></p>
              <a style="color:#ffac4d">Jingyao Li</a>, Han Shi, Xin Jiang, Zhenguo Li, Hong Xu, Jiaya Jia.
              [
              <a href="https://arxiv.org/abs/2406.07528" target="blank_">Paper</a> /
              <a href="https://github.com/dvlab-research/Q-LLM">Code</a>
              ]
            </td>
          </tr>

          <tr class="single_element" style="width:100%">
            <td style="padding:20px;width:100%;vertical-align:middle">
              <papertitle>(CVPR2025)</papertitle> Visionzip: Longer is better but not necessary in vision language models
              <br>
              <p></p>
              Senqiao Yang, Yukang Chen, Zhuotao Tian, Chengyao Wang, <a style="color:#ffac4d">Jingyao Li</a>, Bei Yu, Jiaya Jia.
              [
              <a href="https://arxiv.org/pdf/2412.04467" target="blank_">Paper</a> /
              <a href="https://github.com/dvlab-research/VisionZip">Code</a>
              ]
            </td>
          </tr>

          <tr class="single_element" style="width:100%">
            <td style="padding:20px;width:100%;vertical-align:middle">
              <papertitle>(CVPR2025)</papertitle> DreamOmni: Unified Image Generation and Editing
              <br>
              <p></p>
              Bin Xia, Yuechen Zhang, <a style="color:#ffac4d">Jingyao Li</a>, Chengyao Wang, Yitong Wang, Xinglong Wu, Bei Yu, Jiaya Jia.
              [
              <a href="https://arxiv.org/pdf/2412.17098" target="blank_">Paper</a>
              ]
            </td>
          </tr>
          <tr class="single_element" style="width:100%">
            <td style="padding:20px;width:100%;vertical-align:middle">
              <papertitle>(ACL2025)</papertitle> DAPE V2: Process Attention Score as Feature Map for Length Extrapolation
              <br>
              <p></p>
              Chuanyang Zheng, Yihang Gao, Han Shi, Jing Xiong, Jiankai Sun, <a style="color:#ffac4d">Jingyao Li</a>, Minbin Huang, Xiaozhe Ren, Michael Ng, Xin Jiang, Zhenguo Li, Yu Li.
              [
              <a href="https://arxiv.org/abs/2410.04798" target="blank_">Paper</a> /
              <a href="https://github.com/chuanyang-Zheng/DAPE">Code</a>
              ]
            </td>
          </tr>

          <tr class="single_element" style="width:100%">
            <td style="padding:20px;width:100%;vertical-align:middle">
              <papertitle>(ICCV2025)</papertitle> Lyra: An Efficient and Speech-Centric Framework for Omni-Cognition
              <br>
              <p></p>
              Zhisheng Zhong, Chengyao Wang, Yuqi Liu, Senqiao Yang, Longxiang Tang, Yuechen Zhang, <a style="color:#ffac4d">Jingyao Li</a>, Tianyuan Qu, Yanwei Li, Yukang Chen, Shaozuo Yu, Sitong Wu, Eric Lo, Shu Liu, Jiaya Jia.
              [
              <a href="https://arxiv.org/abs/2412.09501" target="blank_">Paper</a> /
              <a href="https://github.com/dvlab-research/Lyra">Code</a> /
              <a href="https://huggingface.co/collections/zszhong/lyra-model-674ea5bb3b39ff8f15de75fc">Models</a> /
              <a href="https://103.170.5.190:17860/">Demo</a> /
              <a href="https://lyra-omni.github.io/">Project Page</a>
              ]
            </td>
          </tr>


          <tr class="single_element" style="width:100%">
            <td style="padding:20px;width:100%;vertical-align:middle">
              <papertitle>(ICCV2025)</papertitle> Improving Image-Text Data Quality Assessment via Neighbor-Augmented Score
              <br>
              <p></p>
              Sitong Wu, Haoru Tan, <a style="color:#ffac4d">Jingyao Li</a>, Bei Yu, Xiaojuan Qi, Jiaya Jia
              <!-- [
              <a href="https://arxiv.org/abs/2412.09501" target="blank_">Paper</a> /
              <a href="https://github.com/dvlab-research/Lyra">Code</a> /
              <a href="https://huggingface.co/collections/zszhong/lyra-model-674ea5bb3b39ff8f15de75fc">Models</a> /
              <a href="https://103.170.5.190:17860/">Demo</a> /
              <a href="https://lyra-omni.github.io/">Project Page</a>
              ] -->
            </td>
          </tr>

          <tr class="single_element" style="width:100%">
            <td style="padding:20px;width:100%;vertical-align:middle">
              <papertitle>(TPAMI2025)</papertitle> VLPose: Bridging the Domain Gap in Pose Estimation with Language-Vision Tuning
              <br>
              <p></p>
              <a style="color:#ffac4d">Jingyao Li</a>, Pengguang Chen, Xuan Ju, Hong Xu, Jiaya Jia.
              [
              <a href="https://arxiv.org/abs/2402.14456" target="blank_">Paper</a> /
              <a href="https://github.com/JulietLJY/VLPose">Code</a>
              ]
            </td>
          </tr>

          <tr class="single_element" style="width:100%">
            <td style="padding:20px;width:100%;vertical-align:middle">
              <papertitle>(EMNLP2025)</papertitle> Logits-Based Finetuning
              <br>
              <p></p>
              <a style="color:#ffac4d">Jingyao Li</a>, Senqiao Yang, Sitong Wu, Han Shi, Chuanyang Zheng, Hong Xu, Jiaya Jia.
            </td>
          </tr>

          <tr class="single_element" style="width:100%">
            <td style="padding:20px;width:100%;vertical-align:middle">
              <papertitle>(NeurIPS2025)</papertitle> DLoFT: Gradient-Decoupled Fine-Tuning for Generalizable Long Chain-of-Thought Reasoning
              <br>
              <p></p>
              Sitong Wu, Haoru Tan, <a style="color:#ffac4d">Jingyao Li</a>, Shaofeng Zhang, Xiaojuan Qi, Bei Yu, Jiaya Jia.
            </td>
          </tr>

          <tr class="single_element" style="width:100%">
            <td style="padding:20px;width:100%;vertical-align:middle">
              <papertitle>(Under Review)</papertitle> MoTCoder: Elevating Large Language Models with Modular of Thought for Challenging Programming Tasks
              <br>
              <p></p>
              <a style="color:#ffac4d">Jingyao Li</a>, Pengguang Chen, Jiaya Jia.
              [
              <a href="https://arxiv.org/abs/2312.15960" target="blank_">Paper</a> /
              <a href="https://huggingface.co/JingyaoLi/MoTCoder-32B-V1.5">Model</a> /
              <a href="https://github.com/dvlab-research/MoTCoder/">Code</a> /
              <a href="https://zhuanlan.zhihu.com/p/1891097350497338692">Coverage</a>
              ]
            </td>
          </tr>

            <tr class="single_element" style="width:100%">
            <td style="padding:20px;width:100%;vertical-align:middle">
              <papertitle>(Under Review)</papertitle> DynamicBench: Evaluating Real-Time Report Generation in Large Language Models
              <br>
              <p></p>
              <a style="color:#ffac4d">Jingyao Li</a>, Hao Sun, Zile Qiao, Yong Jiang, Pengjun Xie, Fei Huang, Hong Xu, Jiaya Jia
              [
              <a href="https://arxiv.org/abs/2506.21343" target="blank_">Paper</a> 
              <!-- <a href="https://huggingface.co/JingyaoLi/MoTCoder-32B-V1.5">Model</a> /
              <a href="https://github.com/dvlab-research/MoTCoder/">Code</a> /
              <a href="https://zhuanlan.zhihu.com/p/1891097350497338692">Coverage</a> -->
              ]
            </td>
          </tr>


          <tr class="single_element" style="width:100%">
            <td style="padding:20px;width:100%;vertical-align:middle">
              <papertitle>(Under Review)</papertitle> RoboCoder: Robotic Learning from Basic Skills to General Tasks with Large Language Models
              <br>
              <p></p>
              <a style="color:#ffac4d">Jingyao Li</a>, Pengguang Chen, Sitong Wu, Chuanyang Zheng, Hong Xu, Jiaya Jia.
              [
              <a href="https://arxiv.org/abs/2406.03757" target="blank_">Paper</a>
              ]
            </td>
          </tr>

        </table>

        <!-- 3 Experiences -->
        <table style="width:100%;padding:3px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:1%;width:100%;vertical-align:middle">
              <heading>Experiences</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:90%;padding:3px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr >
              <td style="padding:10px;width:40%;text-align:left">
                <b>Alibaba Group</b>
              </td>
              <td style="padding:0px;width:40%;text-align:left">
                <em>Research Intern </em>
              </td>
              <td style="padding:0px;width:20%;text-align:right">
                <strong>Aug.2024-present</strong>
              </td>
            </tr>
            <tr >
              <td style="padding:10px;width:40%;text-align:left">
                <b>Huawei Noah's Ark Lab</b>
              </td>
              <td style="padding:0px;width:40%;text-align:left">
                <em>Research Intern </em>
              </td>
              <td style="padding:0px;width:20%;text-align:right">
                <strong>Apr.2024 - Aug.2024</strong>
              </td>
            </tr>
            <tr >
              <td style="padding:10px;width:40%;text-align:left">
                <b>The Chinese University of Hong Kong</b>
              </td>
              <td style="padding:0px;width:40%;text-align:left">
                <em>Ph.D of the Department of Computer Science and Engineering</em> Supervisor: <a href="https://jiaya.me">Jiaya Jia</a>
              </td>
              <td style="padding:0px;width:20%;text-align:right">
                <strong>Aug. 2022 - Jul. 2026</strong>
              </td>
            </tr>
            <tr>
              <td style="padding:10px;width:40%;text-align:left">
                <b>Xi'an Jiaotong University</b>
              </td>
              <td style="padding:0px;width:40%;text-align:left">
                <em>Bachelor of the Department of Automation</em>
              </td>
              <td style="padding:0px;width:20%;text-align:right">
                <strong>Sep. 2018 - Jul. 2022</strong>
              </td>
            </tr>
            <tr>
              <td style="padding:10px;width:40%;text-align:left">
                <b>University of Cambridge</b>
              </td>
              <td style="padding:0px;width:40%;text-align:left">
                <em>Artificial Intelligence and Industry 4.0 Project</em>
              </td>
              <td style="padding:0px;width:20%;text-align:right">
                <strong>Jul. 2019</strong>
              </td>
            </tr>
          </tbody>
        </table>

				<p></p>
        
        <!-- 4 HonorsAndAwards -->
        <!-- <table style="width:100%;padding:3px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:1%;width:100%;vertical-align:middle">
              <heading>Selected Awards</heading>
            </td>
          </tr>
        </tbody></table>
          <ul>
            <li><p>
              National Scholarship, <b>2020</b>
            </p></li>
            <li><p>
              First Prize of China Undergraduate Physics Tournament, <b>2018</b>
            </p></li>
            <li><p>
              Meritorious Winner of American Mathematical Contest in Modeling, <b>2019</b>
            </p></li>
            <li><p>
              Grand Prize of Northwest Undergraduate Physics Tournament, <b>2018</b>
            </p></li>
          </ul>
        
        <p></p> -->

        <!-- 5 Teaching -->
<table style="width:100%;padding:3px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:1%;width:100%;vertical-align:middle">
              <heading>Teaching</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:90%;padding:3px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr >
              <td style="padding:10px;width:40%;text-align:left">
                <b>CENG2010</b>
              </td>
              <td style="padding:0px;width:40%;text-align:left">
                <em>Digital Logic Design Laboratory </em>
              </td>
              <td style="padding:0px;width:20%;text-align:right">
                <strong>2023 Spring</strong>
              </td>
            </tr>
            <tr >
              <td style="padding:10px;width:40%;text-align:left">
                <b>CSCI3250</b>
              </td>
              <td style="padding:0px;width:40%;text-align:left">
                <em>Computers and Society </em>
              </td>
              <td style="padding:0px;width:20%;text-align:right">
                <strong>2022 Fall</strong>
              </td>
            </tr>
          </tbody>
        </table>
      
      </td>
    </tr>
  </table>
</body>

